=== Job started at Sat Feb 28 01:49:40 PM EST 2026 ===
Running on node: babel-q5-32
2026-02-28 13:49:56.911	babel-q5-32:0	train:41	INFO	CLI environment prepared
2026-02-28 13:50:01.099	babel-q5-32:0	py.warnings:109	WARNING	/home/aarusha/miniconda3/envs/molmo/lib/python3.10/site-packages/torch/distributed/c10d_logger.py:83: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.
  return func(*args, **kwargs)

2026-02-28 14:01:01.523	babel-q5-32:0	train:80	INFO	Configuration:
2026-02-28 14:01:01.524	babel-q5-32:0	train:81	INFO	TrainConfig(run_name='multitask_train', seed=6198, epoch=None, dry_run=False, model=ModelConfig(d_model=3584, n_heads=28, n_kv_heads=4, qkv_bias=True, clip_qkv=None, n_layers=28, mlp_ratio=4, mlp_hidden_size=37888, activation_type='swiglu', block_type='sequential', block_group_size=1, rope=True, rope_full_precision=True, rope_theta=1000000.0, vision_backbone=VisionBackboneConfig(image_model_type='openai', image_default_input_size=(336, 336), image_patch_size=14, image_pos_patch_size=14, image_emb_dim=1024, image_num_heads=16, image_num_key_value_heads=16, image_num_layers=23, image_head_dim=64, image_mlp_dim=4096, image_mlp_activations='quick_gelu', image_dropout_rate=0.0, image_num_pos=577, image_norm_eps=1e-05, attention_dropout=0.0, residual_dropout=0.0, initializer_range=0.02, fsdp_wrap=False, resize_mode='default'), vit_load_path='/data/hf_cache/molmo/pretrained_image_encoders/vit-l-14-336.pt', llm_load_path='/data/hf_cache/molmo/pretrained_llms/qwen2-7b.pt', low_cpu_fsdp=True, attention_type='sdpa', float32_attention=True, attention_dropout=0.0, attention_layer_norm=False, residual_dropout=0.0, response_residual_dropout=0.1, embedding_dropout=0.0, layer_norm_type='rms', layer_norm_with_affine=True, layer_norm_eps=1e-06, attention_layer_norm_with_affine=True, max_sequence_length=4096, max_position_embeddings=None, include_bias=False, bias_for_layer_norm=None, scale_logits=False, vocab_size=152064, embedding_size=152064, additional_vocab_size=128, new_embedding_init_range=0.02, weight_tying=False, init_device=None, init_fn='normal', init_std=0.02, init_cutoff_factor=None, norm_after=False, precision='amp_bf16', max_crops=12, crop_mode='overlap-and-resize-c2', use_col_tokens=True, prompt_type='none', system_prompt_kind='style_and_length', message_formatting='none', always_start_with_space=True, multi_annotation_weighting=None, default_inference_len=65, overlap_margins=[4, 4], pad_value=0.0, image_padding_embed='pad_and_partial_pad', fix_image_padding=True, vit_layers=(-2, -9), image_pooling_h=2, image_pooling_w=2, image_pooling_2d='attention_meanq', image_projector='mlp', image_feature_dropout=0.0, initializer_range=0.02, normalize_input_embeds=False, use_position_ids=True, head_dim=None, tokenizer=TokenizerConfig(identifier='Qwen/Qwen2-7B', tokenizer_dir=None), pad_tokenizer=True, moe_num_experts=8, moe_top_k=2, moe_mlp_impl='sparse', moe_log_expert_assignment=False, moe_shared_expert=False, moe_lbl_in_fp32=False, moe_interleave=False, moe_loss_weight=0.1, moe_zloss_weight=None, moe_dropless=True, moe_capacity_factor=1.25), allow_resume=False, ft_llm=True, ft_vit=True, ft_connector=True, ft_embedding='lm_head', optimizer=OptimizerConfig(name='adamw', learning_rate=0.0001, weight_decay=0.01, betas=(0.9, 0.95), eps=1e-05, connector_learning_rate=0.0002, vit_learning_rate=6e-06, llm_learning_rate=2e-05, connector_weight_decay=0.0, vit_weight_decay=0.0, llm_weight_decay=0.0, connector_betas=(0.9, 0.95), vit_betas=(0.9, 0.95), llm_betas=(0.9, 0.95), connector_eps=1e-06, vit_eps=1e-06, llm_eps=1e-06, metrics_log_interval=20), scheduler=SchedulerConfig(name='multimodal', units='steps', t_warmup=100, t_max=None, alpha_f=0.1, connector_t_warmup=200, vit_t_warmup=2000, llm_t_warmup=2000, grad_clip_warmup_steps=None, grad_clip_warmup_factor=None, warmup_min_lr=0.0), data=DataConfig(dataset='pixmo_cap_with_transcripts', mixture=None, root_size_mixture=None, split='train', seed=95818, shuffle_messages=False, pad='to_max', sequence_length=2304, shuffle=True, for_inference=False, multi_modal='torch', num_workers=2, drop_last=True, pin_memory=True, prefetch_factor=None, persistent_workers=False, timeout=0), restore_dataloader=True, fast_forward_batches=None, evaluators=[DatasetEvaluatorConfig(label='val', data=DataConfig(dataset='pixmo_cap_with_transcripts', mixture=None, root_size_mixture=None, split='validation', seed=None, shuffle_messages=False, pad='to_max', sequence_length=2304, shuffle=False, for_inference=False, multi_modal='torch', num_workers=2, drop_last=True, pin_memory=True, prefetch_factor=None, persistent_workers=True, timeout=0), device_eval_batch_size=None, subset_num_batches=64, max_examples=None, max_new_tokens=448, mm_evaluator=None, save_dir=None, save_to_checkpoint_dir=False, eval_name=None, skip_if_metrics_cached=True), DatasetEvaluatorConfig(label='caption_val', data=DataConfig(dataset='pixmo_cap', mixture=None, root_size_mixture=None, split='validation', seed=None, shuffle_messages=False, pad='to_max', sequence_length=2304, shuffle=False, for_inference=False, multi_modal='torch', num_workers=2, drop_last=True, pin_memory=True, prefetch_factor=None, persistent_workers=True, timeout=0), device_eval_batch_size=None, subset_num_batches=64, max_examples=None, max_new_tokens=448, mm_evaluator=None, save_dir=None, save_to_checkpoint_dir=False, eval_name=None, skip_if_metrics_cached=True)], eval_interval=1000, inf_eval_interval=-1, inf_evaluators=[], save_folder='/data/user_data/aarusha/molmo/checkpoints/captioner', remote_save_folder=None, canceled_check_interval=50, save_interval=4000, save_interval_unsharded=19428, save_interval_ephemeral=None, save_num_checkpoints_to_keep=1, save_num_unsharded_checkpoints_to_keep=-1, save_overwrite=True, force_save_unsharded=False, no_pre_train_checkpoint=True, initial_model_checkpoint=None, load_model_config=None, load_path=None, load_path_sharded_checkpointer=None, reset_optimizer_state=False, reset_trainer_state=False, save_dataloader_state=False, reset_dataloader_state=False, sharded_checkpointer='torch_legacy', max_duration=19428, global_train_batch_size=128, device_train_batch_size=16, device_train_microbatch_size=2, device_eval_batch_size=4, eval_subset_num_batches=-1, eval_on_load=False, device_inf_eval_batch_size=16, inf_eval_subset_num_batches=-1, device_train_grad_accum=8, max_grad_norm=1.0, multi_component_grad_norm=True, batch_divisor='global_batch', max_grad_norm_ratio=None, precision='amp_bf16', wandb=None, speed_monitor=SpeedMonitorConfig(window_size=20, gpu_flops_available=None), console_log_interval=20, gen1_gc_interval=1, compile=None, fsdp=FSDPConfig(use_orig_params=True, sharding_strategy=<ShardingStrategy.FULL_SHARD: 1>, wrapping_strategy='by_block_and_size', precision='float', hybrid_sharding_num_model_replicas=None), softmax_auxiliary_loss=True, softmax_auxiliary_loss_scale=0.0001, time_limit=None, extra_steps_after_cancel=10, python_profiling=False, torch_profiling=False, stop_at=19428, stop_after=None, activation_checkpointing='whole_layer', fused_loss=None)
